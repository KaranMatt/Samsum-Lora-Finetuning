{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40ac9402",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\KM\\Virtual ENV\\venv2\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from datasets import Dataset\n",
    "from peft import get_peft_model,LoraConfig\n",
    "from transformers import AutoTokenizer,AutoModelForSeq2SeqLM,Trainer,TrainingArguments,DataCollatorForSeq2Seq,BitsAndBytesConfig\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de68e0fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dialogue</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13818513</td>\n",
       "      <td>Amanda: I baked  cookies. Do you want some?\\r\\...</td>\n",
       "      <td>Amanda baked cookies and will bring Jerry some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13728867</td>\n",
       "      <td>Olivia: Who are you voting for in this electio...</td>\n",
       "      <td>Olivia and Olivier are voting for liberals in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13681000</td>\n",
       "      <td>Tim: Hi, what's up?\\r\\nKim: Bad mood tbh, I wa...</td>\n",
       "      <td>Kim may try the pomodoro technique recommended...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13730747</td>\n",
       "      <td>Edward: Rachel, I think I'm in ove with Bella....</td>\n",
       "      <td>Edward thinks he is in love with Bella. Rachel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13728094</td>\n",
       "      <td>Sam: hey  overheard rick say something\\r\\nSam:...</td>\n",
       "      <td>Sam is confused, because he overheard Rick com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>13828654</td>\n",
       "      <td>Thomas: Sir, we have a problem.\\r\\nMarshall: W...</td>\n",
       "      <td>Thomas is informing Marshall that Broderick Sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>13728621</td>\n",
       "      <td>Rachel: Hi, how are you doing?\\r\\nCharlie: goo...</td>\n",
       "      <td>Charlie is in New York. Rachel will see Charli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>13680705</td>\n",
       "      <td>Estrella: But I will try to get some job in li...</td>\n",
       "      <td>Estrella is going to try and get a job in Lisb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>13728136</td>\n",
       "      <td>Zoe: Hiii\\r\\nSammy: NO\\r\\nZoe: what?\\r\\nSammy:...</td>\n",
       "      <td>Too general; no specific info.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>13727827</td>\n",
       "      <td>Bessie: do you know when rose's birthday is?\\r...</td>\n",
       "      <td>Rose's birthday is on July 7. Bessie is trying...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                           dialogue  \\\n",
       "0     13818513  Amanda: I baked  cookies. Do you want some?\\r\\...   \n",
       "1     13728867  Olivia: Who are you voting for in this electio...   \n",
       "2     13681000  Tim: Hi, what's up?\\r\\nKim: Bad mood tbh, I wa...   \n",
       "3     13730747  Edward: Rachel, I think I'm in ove with Bella....   \n",
       "4     13728094  Sam: hey  overheard rick say something\\r\\nSam:...   \n",
       "...        ...                                                ...   \n",
       "4995  13828654  Thomas: Sir, we have a problem.\\r\\nMarshall: W...   \n",
       "4996  13728621  Rachel: Hi, how are you doing?\\r\\nCharlie: goo...   \n",
       "4997  13680705  Estrella: But I will try to get some job in li...   \n",
       "4998  13728136  Zoe: Hiii\\r\\nSammy: NO\\r\\nZoe: what?\\r\\nSammy:...   \n",
       "4999  13727827  Bessie: do you know when rose's birthday is?\\r...   \n",
       "\n",
       "                                                summary  \n",
       "0     Amanda baked cookies and will bring Jerry some...  \n",
       "1     Olivia and Olivier are voting for liberals in ...  \n",
       "2     Kim may try the pomodoro technique recommended...  \n",
       "3     Edward thinks he is in love with Bella. Rachel...  \n",
       "4     Sam is confused, because he overheard Rick com...  \n",
       "...                                                 ...  \n",
       "4995  Thomas is informing Marshall that Broderick Sp...  \n",
       "4996  Charlie is in New York. Rachel will see Charli...  \n",
       "4997  Estrella is going to try and get a job in Lisb...  \n",
       "4998                     Too general; no specific info.  \n",
       "4999  Rose's birthday is on July 7. Bessie is trying...  \n",
       "\n",
       "[5000 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sam_train=pd.read_csv('Data/samsum-train.csv')\n",
    "sam_train=sam_train.head(7500)\n",
    "sam_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99cf74ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amanda: I baked  cookies. Do you want some?\\r\\...</td>\n",
       "      <td>Amanda baked cookies and will bring Jerry some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Olivia: Who are you voting for in this electio...</td>\n",
       "      <td>Olivia and Olivier are voting for liberals in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tim: Hi, what's up?\\r\\nKim: Bad mood tbh, I wa...</td>\n",
       "      <td>Kim may try the pomodoro technique recommended...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Edward: Rachel, I think I'm in ove with Bella....</td>\n",
       "      <td>Edward thinks he is in love with Bella. Rachel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sam: hey  overheard rick say something\\r\\nSam:...</td>\n",
       "      <td>Sam is confused, because he overheard Rick com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>Thomas: Sir, we have a problem.\\r\\nMarshall: W...</td>\n",
       "      <td>Thomas is informing Marshall that Broderick Sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>Rachel: Hi, how are you doing?\\r\\nCharlie: goo...</td>\n",
       "      <td>Charlie is in New York. Rachel will see Charli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>Estrella: But I will try to get some job in li...</td>\n",
       "      <td>Estrella is going to try and get a job in Lisb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>Zoe: Hiii\\r\\nSammy: NO\\r\\nZoe: what?\\r\\nSammy:...</td>\n",
       "      <td>Too general; no specific info.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>Bessie: do you know when rose's birthday is?\\r...</td>\n",
       "      <td>Rose's birthday is on July 7. Bessie is trying...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "0     Amanda: I baked  cookies. Do you want some?\\r\\...   \n",
       "1     Olivia: Who are you voting for in this electio...   \n",
       "2     Tim: Hi, what's up?\\r\\nKim: Bad mood tbh, I wa...   \n",
       "3     Edward: Rachel, I think I'm in ove with Bella....   \n",
       "4     Sam: hey  overheard rick say something\\r\\nSam:...   \n",
       "...                                                 ...   \n",
       "4995  Thomas: Sir, we have a problem.\\r\\nMarshall: W...   \n",
       "4996  Rachel: Hi, how are you doing?\\r\\nCharlie: goo...   \n",
       "4997  Estrella: But I will try to get some job in li...   \n",
       "4998  Zoe: Hiii\\r\\nSammy: NO\\r\\nZoe: what?\\r\\nSammy:...   \n",
       "4999  Bessie: do you know when rose's birthday is?\\r...   \n",
       "\n",
       "                                                summary  \n",
       "0     Amanda baked cookies and will bring Jerry some...  \n",
       "1     Olivia and Olivier are voting for liberals in ...  \n",
       "2     Kim may try the pomodoro technique recommended...  \n",
       "3     Edward thinks he is in love with Bella. Rachel...  \n",
       "4     Sam is confused, because he overheard Rick com...  \n",
       "...                                                 ...  \n",
       "4995  Thomas is informing Marshall that Broderick Sp...  \n",
       "4996  Charlie is in New York. Rachel will see Charli...  \n",
       "4997  Estrella is going to try and get a job in Lisb...  \n",
       "4998                     Too general; no specific info.  \n",
       "4999  Rose's birthday is on July 7. Bessie is trying...  \n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sam_train.columns=['id','text','summary']\n",
    "sam_train=sam_train.iloc[:,1:]\n",
    "sam_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ed88b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds=Dataset.from_pandas(df=sam_train)\n",
    "split=ds.train_test_split(test_size=0.2,seed=42)\n",
    "train_df=split['train']\n",
    "test_df=split['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f863d4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL='google/flan-t5-base'\n",
    "tokenizer=AutoTokenizer.from_pretrained(MODEL,use_fast=True)\n",
    "bnb_config=BitsAndBytesConfig(load_in_8bit=True)\n",
    "model=AutoModelForSeq2SeqLM.from_pretrained(MODEL,quantization_config=bnb_config,device_map='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6ec1d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_len=512\n",
    "out_len=128\n",
    "\n",
    "def preprocess_batch(ex):\n",
    "    instruction=f'Summarise:{ex[\"text\"]}'\n",
    "    inp_tok=tokenizer(instruction,truncation=True,max_length=in_len)\n",
    "    target_summary=ex['summary']+tokenizer.eos_token\n",
    "    out_tok=tokenizer(text_target=target_summary,truncation=True,max_length=out_len)\n",
    "    labels=[(tok if tok!=tokenizer.pad_token_id else -100) for tok in out_tok['input_ids']]\n",
    "    return {'input_ids':inp_tok['input_ids'],'attention_mask':inp_tok['attention_mask'],'labels':labels}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd131c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 4000/4000 [00:01<00:00, 2100.18 examples/s]\n",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 2043.06 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_train=train_df.map(preprocess_batch,remove_columns=train_df.column_names)\n",
    "tokenized_test=test_df.map(preprocess_batch,remove_columns=test_df.column_names)\n",
    "tokenized_train.set_format(type='torch')\n",
    "tokenized_test.set_format(type='torch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84d96881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,769,472 || all params: 249,347,328 || trainable%: 0.7096\n"
     ]
    }
   ],
   "source": [
    "lora_config=LoraConfig(\n",
    "    r=16,lora_alpha=32,lora_dropout=0.05,bias=\"none\",task_type='SEQ_2_SEQ_LM',target_modules=[\"q\",\"v\"]\n",
    ")\n",
    "model=get_peft_model(model,lora_config)\n",
    "model.print_trainable_parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10e2539e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KARAN MATTOO\\AppData\\Local\\Temp\\ipykernel_21256\\4060611941.py:21: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"pt\")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./flan_t5_lora_out\",\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    eval_accumulation_steps=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=1e-4,\n",
    "    fp16=True,\n",
    "    logging_steps=20,\n",
    "    eval_strategy=\"no\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=200,\n",
    "    save_total_limit=2,\n",
    "    remove_unused_columns=False,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9345f2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\KM\\Virtual ENV\\venv2\\Lib\\site-packages\\transformers\\data\\data_collator.py:740: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:281.)\n",
      "  batch[\"labels\"] = torch.tensor(batch[\"labels\"], dtype=torch.int64)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1500/1500 22:50, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>12.017900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>10.402200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>7.382800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>12.881800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>8.338700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>6.676500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>5.940200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>8.146600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>7.089000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>7.011600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>9.518900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>8.130200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>7.584500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>9.040100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>8.613200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>6.994900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>7.189100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>11.352800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>7.303200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>7.948800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>7.997700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>7.624200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>10.416500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>10.474600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>7.549000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>13.367600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>6.750900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>8.317400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>10.257700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>8.488600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>9.285100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>7.821500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>7.868100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>7.436400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>8.693400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>8.099900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>5.868200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>8.056900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>9.362900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>7.716400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>7.047300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>10.324000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>7.018500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>9.470300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>13.641000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>9.026000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>10.486700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>10.490300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>8.350500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>10.622900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>7.084100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1040</td>\n",
       "      <td>8.249900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1060</td>\n",
       "      <td>9.885500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>7.198300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>9.193400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1120</td>\n",
       "      <td>6.853500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>7.990300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1160</td>\n",
       "      <td>8.449200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1180</td>\n",
       "      <td>8.740900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>7.234800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1220</td>\n",
       "      <td>8.088500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1240</td>\n",
       "      <td>6.994800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>8.093100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1280</td>\n",
       "      <td>11.549800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>7.798700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>9.726600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1340</td>\n",
       "      <td>6.508900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1360</td>\n",
       "      <td>11.211900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>6.603100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>8.324400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1420</td>\n",
       "      <td>7.429900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>8.692100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1460</td>\n",
       "      <td>11.491500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1480</td>\n",
       "      <td>7.568700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>6.638900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1500, training_loss=8.601260864257812, metrics={'train_runtime': 1371.9083, 'train_samples_per_second': 8.747, 'train_steps_per_second': 1.093, 'total_flos': 3378924243929088.0, 'train_loss': 8.601260864257812, 'epoch': 3.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a343b259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting memory-safe inference on 1000 samples (Batch Size: 4)...\n",
      "Processed 4 samples...\n",
      "Processed 204 samples...\n",
      "Processed 404 samples...\n",
      "Processed 604 samples...\n",
      "Processed 804 samples...\n",
      "\n",
      "--- Final ROUGE Results (Memory-Safe) ---\n",
      "{'rouge1': np.float64(0.45351973443715454), 'rouge2': np.float64(0.2125908276921321), 'rougeL': np.float64(0.3736699292557541), 'rougeLsum': np.float64(0.3733172262480615)}\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Imports and Setup ---\n",
    "import torch\n",
    "import evaluate\n",
    "from datasets import Dataset\n",
    "\n",
    "# Assuming 'model' and 'tokenizer' are already loaded with LoRA adapters\n",
    "# If you re-started your notebook, reload your model like this:\n",
    "# from peft import PeftModel\n",
    "# model = PeftModel.from_pretrained(model, \"./flan_t5_lora_final\") \n",
    "# model = model.to('cuda') # Ensure the model is on the GPU\n",
    "\n",
    "# Use a batch size of 1 to minimize VRAM usage during generation\n",
    "SAFE_BATCH_SIZE = 4\n",
    "# We use the original test_df dataframe (from Cell 3/4)\n",
    "test_data_samples = test_df \n",
    "\n",
    "# --- 2. Manual Inference Loop ---\n",
    "\n",
    "predictions = []\n",
    "reference_summaries = []\n",
    "\n",
    "print(f\"Starting memory-safe inference on {len(test_data_samples)} samples (Batch Size: {SAFE_BATCH_SIZE})...\")\n",
    "\n",
    "# Loop through the test data, processing one sample (or SAFE_BATCH_SIZE samples) at a time\n",
    "for i in range(0, len(test_data_samples), SAFE_BATCH_SIZE):\n",
    "    \n",
    "    # Select the current batch chunk from the dataset\n",
    "    batch_chunk = test_data_samples.select(range(i, min(i + SAFE_BATCH_SIZE, len(test_data_samples))))\n",
    "    \n",
    "    # Format the input using your instruction tuning prefix\n",
    "    input_texts = [f'Summarize:{ex[\"text\"]}' for ex in batch_chunk]\n",
    "    \n",
    "    # Tokenize the batch and move to the GPU\n",
    "    # NOTE: Padding=True is essential here, even for batch size 1, \n",
    "    # as it ensures the input tensor is correctly structured.\n",
    "    input_batch = tokenizer(\n",
    "        input_texts, \n",
    "        return_tensors=\"pt\", \n",
    "        padding=True, \n",
    "        truncation=True, \n",
    "        max_length=512 # Match your new max_in length\n",
    "    ).to(model.device)\n",
    "    \n",
    "    # === GENERATION (THE MEMORY-INTENSIVE PART) ===\n",
    "    with torch.no_grad(): # Disable gradient calculation for inference\n",
    "        outputs = model.generate(\n",
    "            **input_batch,\n",
    "            max_length=64, # Your desired output length\n",
    "            num_beams=4,   # Use beam search for higher quality\n",
    "            do_sample=False\n",
    "        )\n",
    "    \n",
    "    # Decode outputs and append\n",
    "    decoded_preds = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    predictions.extend(decoded_preds)\n",
    "    reference_summaries.extend(batch_chunk['summary'])\n",
    "    \n",
    "    # Optional: Print progress\n",
    "    if (i // SAFE_BATCH_SIZE) % 50 == 0:\n",
    "        print(f\"Processed {i + SAFE_BATCH_SIZE} samples...\")\n",
    "\n",
    "# --- 3. Final ROUGE Scoring ---\n",
    "\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "# Post-processing function to clean text for accurate ROUGE scoring\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [p.strip() for p in preds]\n",
    "    labels = [l.strip() for l in labels]\n",
    "    return preds, labels\n",
    "\n",
    "clean_preds, clean_labels = postprocess_text(predictions, reference_summaries)\n",
    "\n",
    "# Calculate the final metrics\n",
    "final_rouge_results = rouge.compute(\n",
    "    predictions=clean_preds, \n",
    "    references=clean_labels, \n",
    "    use_stemmer=True\n",
    ")\n",
    "\n",
    "print(\"\\n--- Final ROUGE Results (Memory-Safe) ---\")\n",
    "print(final_rouge_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
